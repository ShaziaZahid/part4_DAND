{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "wrangle_report\n",
    "## Data Wrangling Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "Real-world data rarely comes clean. Using Python and its libraries, you will gather data from a variety of sources and in a variety of formats, assess its quality and tidiness, then clean it. This is called data wrangling. You will document your wrangling efforts in a Jupyter Notebook, plus showcase them through analyses and visualizations using Python (and its libraries) and/or SQL.\n",
    "\n",
    "The dataset that you will be wrangling (and analyzing and visualizing) is the tweet archive of Twitter user @dog_rates, also known as WeRateDogs. WeRateDogs is a Twitter account that rates people's dogs with a humorous comment about the dog. These ratings almost always have a denominator of 10. The numerators, though? Almost always greater than 10. 11/10, 12/10, 13/10, etc. Why? Because \"they're good dogs Brent.\" WeRateDogs has over 4 million followers and has received international media coverage.\n",
    "\n",
    "WeRateDogs downloaded their Twitter archive and sent it to Udacity via email exclusively for you to use in this project. This archive contains basic tweet data (tweet ID, timestamp, text, etc.) for all 5000+ of their tweets as they stood on August 1, 2017. More on this soon."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Goal\n",
    "\n",
    "wrangle WeRateDogs Twitter data to create interesting and trustworthy analyses and visualizations. The Twitter archive is great, but it only contains very basic tweet information. Additional gathering, then assessing and cleaning is required for \"Wow!\"-worthy analyses and visualizations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Data\n",
    "\n",
    "1. Enhanced Twitter Archive: The WeRateDogs Twitter archive contains basic tweet data for all 5000+ of their tweets. It was provided as a csv file by Udacity.\n",
    "    \n",
    "\n",
    "2. Image Predictions File: This file was hosted on Udacity server and was downloaded programitically.\n",
    "\n",
    "\n",
    "3. Additional Data via the Twitter API: This additional data was to be gathered by from Twitter's API. But used given text file and treated it as JSON file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assessing\n",
    "\n",
    "After assessing visually and programitically using a veriety of Pandas functions like info(), count(), value_counts() and describe() etc. found following issues in data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quality Issues\n",
    "\n",
    "1. In df_1 \"retweeted_status_id\" I think these are re-tweets.delete these rows.\n",
    "\n",
    "2. In df_1 After deleting retweeted_status_id rows,some columns will not meet single variable rule like\n",
    "    a. retweeted_status_id\n",
    "    b. retweeted_status_user_id\n",
    "    c. retweeted_status_timestamp\n",
    "\n",
    "\n",
    "3. In df_1 timestamp datatype is string object.Covert it to datetime.\n",
    "\n",
    "4. in_reply_to_status_id and in_reply_to_user_id to data type should be same as tweet_id i.e integer.\n",
    "\n",
    "5. Few (14) rows have two dog stages for one dog.\n",
    "\n",
    "6. I am unable to understand Rating numerators.Some rating numerators are relatively high.\n",
    "\n",
    "7. In text, dogs have ratings in decimal but datatype for ratings is integer.\n",
    "\n",
    "8. Rating denominators do not make sense to me.Some denominators are relatively high.\n",
    "\n",
    "9. df1, df2, and df3 does not have same number of rows. Looks like images are missing from df2 and some extra rows in df2.\n",
    "\n",
    "10. In df_2 The dog breed name values in the p1, p2, and p3 columns are not consistant.\n",
    "\n",
    "11. In df_1, source column has hyperlinks.It needs only source name.\n",
    "\n",
    "12. In df_1, some dog names are not actually names. For example names are \"None\" for 745 dogs.55 dogs have name \"a\"\n",
    "\n",
    "13. Column headers should be more descriptive (examples of non-descriptive column header are img_num, p1, p1_conf, p1_dog, etc.)\n",
    "*Make sure that capitalization of the values is uniform and replace the underscores with spaces for readability.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Structural Issues (Tidiness)\n",
    "\n",
    "1. In df_1, dog stages columns should be one column with four stages in it.\n",
    "\n",
    "2. Merging three data files into one for analysis.(Each type of observational unit should form a table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning\n",
    " For each issue found in assessing I used Define, Code and Test plan for cleaning. Resolved most of the issues and prepared a cleaner dataset. Stored cleaned dataset into csv file as advised by Udacity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
